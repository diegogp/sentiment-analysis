{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd03e9b354ce98f47c9dd0b59702fdeb863bfffe347fccce27b4aea934dfd1532aa",
   "display_name": "Python 3.7.10 64-bit ('sentiment-analysis': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3e9b354ce98f47c9dd0b59702fdeb863bfffe347fccce27b4aea934dfd1532aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import utils\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Embedding, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_ngrams(df, n_words=None, ngram_range=(1, 1)):\n",
    "    ngram_vectorizer = CountVectorizer(analyzer='word', ngram_range=ngram_range, min_df=1)\n",
    "    count_vectors = ngram_vectorizer.fit_transform(df['preprocessed_text'])\n",
    "    vocab = list(ngram_vectorizer.get_feature_names())\n",
    "    if n_words == None:\n",
    "        n_words = len(vocab)\n",
    "    counts = count_vectors.sum(axis=0).A1\n",
    "    freq_distribution = Counter(dict(zip(vocab, counts)))\n",
    "    return freq_distribution.most_common(n_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"tweets.db\")\n",
    "sql = \"select id_str, text from tweets where text not like '%RT @%' order by random() limit 10000\"\n",
    "df = pd.read_sql(sql, con=con, index_col=\"id_str\")\n",
    "df = utils.preprocess(df)\n",
    "df.drop_duplicates(subset=['preprocessed_text'], inplace=True)\n",
    "df = df[df.preprocessed_text.apply(len) > 0]\n",
    "most_common_ngrams = get_most_common_ngrams(df, n_words=None, ngram_range=(1,1))\n",
    "most_common_ngrams_df = pd.DataFrame(most_common_ngrams, columns=['term', 'frequency'])\n",
    "#most_common_ngrams_df.sort_values(by='frequency').plot(kind='barh', x='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['nao quer dizer bexiga nenhuma mas o cara ve a escalacao e nao ha como pensar diferente o e sim superior ao',\n",
       " 'gol em cima do rodinei obrigado elusmar por ter pagado milhao pro flamengo',\n",
       " 'quinta junto com o do flamengo e inter',\n",
       " 'flamengo eu te amo',\n",
       " 'e que vc nao falou de quem tava falando neh enzin pro flamengo ser campeao gtprecisalt ganhar do sp ou o',\n",
       " 'prefiro mil vezes o inter do que o flamengo',\n",
       " 'vamosssessss flamengo',\n",
       " 'pra cima deles flamengo',\n",
       " 'flamengo quer me matar nao e possivel',\n",
       " 'eu to ok pq eu sei que eu nao vou conseguir dormir tao cedo pq meu pai nao sabe assistir o jogo do flamengo com a b']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.preprocessed_text.to_list()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8831\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(most_common_ngrams_df.term)\n",
    "print(VOCAB_SIZE)\n",
    "encoded_text = [one_hot(text, VOCAB_SIZE) for text in df.preprocessed_text.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[8280,\n",
       "  3315,\n",
       "  2774,\n",
       "  4547,\n",
       "  9,\n",
       "  1398,\n",
       "  856,\n",
       "  2781,\n",
       "  2353,\n",
       "  1921,\n",
       "  2580,\n",
       "  2391,\n",
       "  8280,\n",
       "  5231,\n",
       "  1462,\n",
       "  2252,\n",
       "  243,\n",
       "  856,\n",
       "  2391,\n",
       "  1107,\n",
       "  3149,\n",
       "  871],\n",
       " [3385, 8061, 8068, 7079, 5208, 4993, 5404, 8098, 581, 4110, 6661, 6527, 3056],\n",
       " [3325, 269, 7806, 856, 7079, 3056, 2391, 3428],\n",
       " [3056, 1647, 890, 8404],\n",
       " [2391,\n",
       "  3338,\n",
       "  6147,\n",
       "  8280,\n",
       "  8400,\n",
       "  8822,\n",
       "  3445,\n",
       "  2289,\n",
       "  2067,\n",
       "  5969,\n",
       "  1138,\n",
       "  6527,\n",
       "  3056,\n",
       "  2457,\n",
       "  2310,\n",
       "  3473,\n",
       "  3311,\n",
       "  7079,\n",
       "  8462,\n",
       "  4309,\n",
       "  856],\n",
       " [982, 8551, 7064, 856, 3428, 7079, 3338, 856, 3056],\n",
       " [6934, 3056],\n",
       " [2071, 8068, 7484, 3056],\n",
       " [3056, 3315, 7067, 5860, 8280, 2391, 1607],\n",
       " [1647,\n",
       "  1125,\n",
       "  3736,\n",
       "  6711,\n",
       "  1647,\n",
       "  2014,\n",
       "  3338,\n",
       "  1647,\n",
       "  8280,\n",
       "  2846,\n",
       "  5441,\n",
       "  6701,\n",
       "  8657,\n",
       "  8000,\n",
       "  6711,\n",
       "  1986,\n",
       "  4913,\n",
       "  8280,\n",
       "  7692,\n",
       "  6768,\n",
       "  856,\n",
       "  6833,\n",
       "  7079,\n",
       "  3056,\n",
       "  7806,\n",
       "  1921,\n",
       "  4835]]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "encoded_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGHT = max([len(text) for text in df.preprocessed_text.to_list()])\n",
    "print(MAX_LENGHT)\n",
    "padded_texts = pad_sequences(encoded_text, maxlen=MAX_LENGHT, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "padded_texts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 10\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, DIM, input_length=MAX_LENGHT))\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 140, 10)           88310     \n=================================================================\nTotal params: 88,310\nTrainable params: 88,310\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[-8.3264001e-03, -1.0250248e-02, -4.1753866e-02, ...,\n",
       "         -4.6131779e-02, -1.2025215e-02,  2.0456102e-02],\n",
       "        [-3.9486717e-02,  1.7496396e-02,  2.1687079e-02, ...,\n",
       "          1.0509975e-03,  3.0942742e-02,  4.7593858e-02],\n",
       "        [ 3.0824963e-02, -1.2705039e-02, -2.1551406e-02, ...,\n",
       "         -3.1166626e-02, -3.7197806e-02,  1.7631650e-03],\n",
       "        ...,\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02]],\n",
       "\n",
       "       [[-1.9937551e-02, -2.4822926e-02,  4.8705649e-02, ...,\n",
       "         -1.9789755e-02,  2.4919007e-02,  3.8827989e-02],\n",
       "        [-9.0816841e-03,  1.1801530e-02,  8.6209774e-03, ...,\n",
       "          4.6967123e-02, -3.7279535e-02, -7.5995103e-03],\n",
       "        [-3.7533499e-02,  1.4815558e-02,  4.8346285e-02, ...,\n",
       "         -4.2980075e-02, -4.5372080e-02, -9.6342713e-04],\n",
       "        ...,\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02]],\n",
       "\n",
       "       [[ 2.6111726e-02,  3.0474458e-02, -1.0034751e-02, ...,\n",
       "         -2.1063054e-02,  2.6422154e-02, -4.1337442e-02],\n",
       "        [-2.3128225e-02, -2.2995448e-02, -3.1042743e-02, ...,\n",
       "         -3.4206107e-02, -3.2778598e-02,  4.6553005e-02],\n",
       "        [-2.7701367e-02,  4.6267513e-02, -4.9586143e-02, ...,\n",
       "          2.3353886e-02, -3.4256447e-02, -3.7076700e-02],\n",
       "        ...,\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.4793341e-03,  7.3897466e-03, -1.1257935e-02, ...,\n",
       "         -4.4916082e-02,  4.4220913e-02, -1.0655642e-02],\n",
       "        [-4.3006252e-02,  4.9456764e-02, -4.2458884e-03, ...,\n",
       "          5.8634207e-04, -4.4256974e-02,  1.4608491e-02],\n",
       "        [ 1.0209419e-02, -3.7611235e-02, -4.9960837e-03, ...,\n",
       "         -3.6206804e-02, -1.1102747e-02,  3.8735297e-02],\n",
       "        ...,\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02]],\n",
       "\n",
       "       [[ 3.0371930e-02,  1.8012833e-02, -1.4758430e-02, ...,\n",
       "         -4.0156733e-02,  4.1875470e-02, -4.9338020e-02],\n",
       "        [ 6.1176717e-05, -3.2947898e-02,  3.1912912e-02, ...,\n",
       "         -5.0306320e-04, -3.7833799e-02, -4.8274554e-02],\n",
       "        [-4.8609164e-02,  4.1010726e-02,  7.1328878e-04, ...,\n",
       "          2.3712739e-03, -3.0367006e-02,  1.7718945e-02],\n",
       "        ...,\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02]],\n",
       "\n",
       "       [[-5.3406581e-03, -6.5786131e-03,  2.7646217e-02, ...,\n",
       "          2.9055152e-02,  1.4764294e-03,  2.9729497e-02],\n",
       "        [-4.0976502e-02,  4.9822662e-02,  4.8489857e-02, ...,\n",
       "         -4.7514796e-02, -2.9953694e-02,  4.2392816e-02],\n",
       "        [ 1.6248021e-02,  1.3986755e-02,  4.5545828e-02, ...,\n",
       "         -4.0961634e-02, -2.8814554e-02,  3.6062721e-02],\n",
       "        ...,\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02],\n",
       "        [-1.1120796e-02,  4.6502355e-02,  2.3416627e-02, ...,\n",
       "         -2.0029986e-02,  4.1103516e-02, -3.8796999e-02]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.predict(padded_texts)"
   ]
  }
 ]
}