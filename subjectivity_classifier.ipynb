{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd03e9b354ce98f47c9dd0b59702fdeb863bfffe347fccce27b4aea934dfd1532aa",
   "display_name": "Python 3.7.10 64-bit ('sentiment-analysis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Diego\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = pd.read_excel('data.xlsx')\n",
    "    print(\"\\n\")\n",
    "    print('Loading Dataset shape: {}'.format(dataset.shape))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_lazy_classifier(X, y, vectorizer):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                            y, stratify=y, random_state=0)\n",
    "    \n",
    "    X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = clf.fit(X_train_vectors.A, X_test_vectors.A, y_train, y_test)\n",
    "    print(\"\\n\")\n",
    "    #get best F1 Score model\n",
    "    models = models.sort_values(by=['ROC AUC'] , ascending=False)\n",
    "    print(models)\n",
    "    print(\"Best Model: {}\".format(models.index[0]))\n",
    "    best_model = clf.models[models.index[0]]\n",
    "    return vectorizer, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]\n",
      "\n",
      "Loading Dataset shape: (1111, 5)\n",
      "100%|██████████| 29/29 [00:21<00:00,  1.36it/s]\n",
      "\n",
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LogisticRegression                 0.71               0.66     0.66      0.71   \n",
      "NearestCentroid                    0.70               0.65     0.65      0.70   \n",
      "GaussianNB                         0.64               0.65     0.65      0.66   \n",
      "LinearSVC                          0.68               0.64     0.64      0.69   \n",
      "NuSVC                              0.74               0.63     0.63      0.71   \n",
      "BernoulliNB                        0.73               0.63     0.63      0.71   \n",
      "Perceptron                         0.67               0.63     0.63      0.67   \n",
      "PassiveAggressiveClassifier        0.68               0.63     0.63      0.68   \n",
      "SGDClassifier                      0.74               0.62     0.62      0.71   \n",
      "ExtraTreeClassifier                0.68               0.62     0.62      0.67   \n",
      "ExtraTreesClassifier               0.72               0.61     0.61      0.69   \n",
      "LGBMClassifier                     0.69               0.60     0.60      0.67   \n",
      "RandomForestClassifier             0.72               0.60     0.60      0.68   \n",
      "AdaBoostClassifier                 0.69               0.59     0.59      0.67   \n",
      "XGBClassifier                      0.69               0.59     0.59      0.67   \n",
      "KNeighborsClassifier               0.73               0.58     0.58      0.66   \n",
      "RidgeClassifierCV                  0.60               0.57     0.57      0.61   \n",
      "LinearDiscriminantAnalysis         0.57               0.57     0.57      0.58   \n",
      "BaggingClassifier                  0.68               0.57     0.57      0.65   \n",
      "RidgeClassifier                    0.56               0.56     0.56      0.58   \n",
      "SVC                                0.71               0.56     0.56      0.64   \n",
      "DecisionTreeClassifier             0.61               0.55     0.55      0.61   \n",
      "QuadraticDiscriminantAnalysis      0.44               0.54     0.54      0.42   \n",
      "DummyClassifier                    0.59               0.52     0.52      0.59   \n",
      "LabelSpreading                     0.69               0.51     0.51      0.57   \n",
      "LabelPropagation                   0.69               0.51     0.51      0.57   \n",
      "CalibratedClassifierCV             0.69               0.50     0.50      0.56   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "LogisticRegression                   0.28  \n",
      "NearestCentroid                      0.12  \n",
      "GaussianNB                           0.08  \n",
      "LinearSVC                            1.67  \n",
      "NuSVC                                1.93  \n",
      "BernoulliNB                          0.12  \n",
      "Perceptron                           0.18  \n",
      "PassiveAggressiveClassifier          0.19  \n",
      "SGDClassifier                        0.17  \n",
      "ExtraTreeClassifier                  0.10  \n",
      "ExtraTreesClassifier                 1.27  \n",
      "LGBMClassifier                       0.35  \n",
      "RandomForestClassifier               0.82  \n",
      "AdaBoostClassifier                   0.98  \n",
      "XGBClassifier                        1.60  \n",
      "KNeighborsClassifier                 0.50  \n",
      "RidgeClassifierCV                    0.51  \n",
      "LinearDiscriminantAnalysis           1.36  \n",
      "BaggingClassifier                    1.12  \n",
      "RidgeClassifier                      0.19  \n",
      "SVC                                  1.45  \n",
      "DecisionTreeClassifier               0.17  \n",
      "QuadraticDiscriminantAnalysis        0.71  \n",
      "DummyClassifier                      0.08  \n",
      "LabelSpreading                       0.15  \n",
      "LabelPropagation                     0.13  \n",
      "CalibratedClassifierCV               5.07  \n",
      "Best Model: LogisticRegression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "dataset = utils.preprocess(dataset)\n",
    "X, y = dataset['preprocessed_text'], dataset['target']\n",
    "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1,1))\n",
    "vectorizer, best_model = train_test_lazy_classifier(X, y, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    " 'tfidf__max_features':[200, 500, 1000, 2000],\n",
    " 'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3)],\n",
    " 'log_reg__C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(log_reg_pipe, cv=5, param_grid=params, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('log_reg', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'log_reg__C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
       "                         'tfidf__max_features': [200, 500, 1000, 2000],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 3),\n",
       "                                                (2, 3), (3, 3)]},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 3))),\n",
       "                ('log_reg', LogisticRegression(C=100.0))])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best score: 0.485\nBest parameters set:\n\tlog_reg__C: 100.0\n\ttfidf__max_features: 1000\n\ttfidf__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.75      0.77      0.76       191\n           1       0.46      0.43      0.44        87\n\n    accuracy                           0.67       278\n   macro avg       0.60      0.60      0.60       278\nweighted avg       0.66      0.67      0.66       278\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "log_reg_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = log_reg_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.73      0.96      0.83       191\n           1       0.69      0.21      0.32        87\n\n    accuracy                           0.72       278\n   macro avg       0.71      0.58      0.57       278\nweighted avg       0.72      0.72      0.67       278\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  }
 ]
}