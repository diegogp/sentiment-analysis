{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd05269e6b9e2975eb3b122cde3fd2cf669a9b5e3fde7c7f789945efb52d7fd6e83",
   "display_name": "Python 3.8.2 64-bit ('sentimengo': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5269e6b9e2975eb3b122cde3fd2cf669a9b5e3fde7c7f789945efb52d7fd6e83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import emoji\n",
    "import nltk\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from enelvo.normaliser import Normaliser\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "from texthero import preprocessing\n",
    "import texthero as hero\n",
    "from liwc import Liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/diego/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "nltk.download('punkt')\n",
    "#classes = ['VERB', 'NOUN', 'ADJ']\n",
    "LIWCLocation = 'LIWC2015.dic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return key for any value\n",
    "def get_key(classes, my_dict):\n",
    "    keys = []\n",
    "    for _class in classes:\n",
    "        for key, value in my_dict.items():\n",
    "            if _class == value:\n",
    "                keys.append(key)\n",
    "    \n",
    "    return \" \".join(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pos_tagger(text):\n",
    "#     doc = nlp(text)\n",
    "#     pos_tagging_dict = {}\n",
    "#     for token in doc:\n",
    "#         pos_tagging_dict[token.text] = token.pos_\n",
    "#     return pos_tagging_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatize(text):\n",
    "#     doc = nlp(text)\n",
    "#     lemma_list = []\n",
    "#     for token in doc:\n",
    "#         lemma_list.append(token.lemma_)\n",
    "#     return \" \".join(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=\"portuguese\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI[\"pt\"]]\n",
    "    text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    pattern = r\"@[a-zA-Z0-9]+\"\n",
    "    text = re.sub(pattern, \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(text):\n",
    "    pattern = r\"#[a-zA-Z0-9]+\"\n",
    "    text = re.sub(pattern, \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quotes(text):\n",
    "    text = re.sub(r\"\"\"['\"]+\"\"\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liwc_analysis(text):\n",
    "    liwc = Liwc(LIWCLocation)\n",
    "    tokens = tokenize(text)\n",
    "    liwc_analysis = dict(liwc.parse(tokens))\n",
    "    return liwc_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subjectivity(liwc_analysis):    \n",
    "    classes = ['compare (Comparisons)', \n",
    "               'affect (Affect)',\n",
    "               'posemo (Positive Emotions)', \n",
    "               'negemo (Negative Emotions)']\n",
    "    for class_ in classes:\n",
    "        if class_ in liwc_analysis:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sentiment_words_rate(text):\n",
    "#     senti_dict = {\"posemo\": 0,\n",
    "#                   \"negemo\": 0}\n",
    "#     tokens = nltk.tokenize.word_tokenize(text, language=\"portuguese\")\n",
    "#     if len(tokens) > 0:\n",
    "#         for token in tokens:\n",
    "#             if token in liwc:\n",
    "#                 if \"posemo\" in liwc[token]:\n",
    "#                     senti_dict[\"posemo\"] += 1\n",
    "#                 elif \"negemo\" in liwc[token]:\n",
    "#                     senti_dict[\"negemo\"] += 1\n",
    "#         senti_dict[\"posemo\"] = round(senti_dict[\"posemo\"] / len(tokens), 2)\n",
    "#         senti_dict[\"negemo\"] = round(senti_dict[\"negemo\"] / len(tokens), 2)\n",
    "#     return senti_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalizer = Normaliser()\n",
    "    text = normalizer.normalise(text)\n",
    "    #text = text.replace('username', '')\n",
    "    #text = text.replace('hashtag', '')\n",
    "    #text = text.replace('number', '')\n",
    "    #text = text.replace('url', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['preprocessed_text'] = df.text.apply(remove_urls)\n",
    "    df['preprocessed_text'] = df.preprocessed_text.apply(remove_tags)\n",
    "    df['preprocessed_text'] = df.preprocessed_text.apply(remove_hashtags)\n",
    "    df['preprocessed_text'] = df.preprocessed_text.apply(remove_emoji)\n",
    "    df['preprocessed_text'] = df.preprocessed_text.apply(remove_quotes)\n",
    "\n",
    "    custom_pipeline = [preprocessing.fillna,\n",
    "                       preprocessing.lowercase,\n",
    "                       preprocessing.remove_brackets,\n",
    "                       preprocessing.remove_digits,\n",
    "                       preprocessing.remove_punctuation,\n",
    "                       preprocessing.remove_whitespace]\n",
    "    df['preprocessed_text'] = df.preprocessed_text.pipe(hero.clean, custom_pipeline)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_dataset_with_sentiment_words(df):\n",
    "#     df[\"sentiment_words_rate\"] = df.preprocessed_text.apply(get_sentiment_words_rate)\n",
    "#     df[\"posemo_rate\"] = df.sentiment_words_rate.apply(lambda x: x[\"posemo\"])\n",
    "#     df[\"negemo_rate\"] = df.sentiment_words_rate.apply(lambda x: x[\"negemo\"])\n",
    "#     df = df[(df.posemo_rate > 0) | (df.negemo_rate > 0)]\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    con = sqlite3.connect(\"tweets.db\")\n",
    "    sql = \"select id_str, text from tweets where text not like '%RT @%' order by random() limit 2000\"\n",
    "    df = pd.read_sql(sql, con=con, index_col=\"id_str\")\n",
    "    df = preprocess(df)\n",
    "    df['liwc_analysis'] = df.preprocessed_text.apply(get_liwc_analysis)\n",
    "    df['is_subjective'] = df.liwc_analysis.apply(check_subjectivity)\n",
    "    #df = filter_dataset_with_sentiment_words(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                  text  \\\n",
       "id_str                                                                   \n",
       "1365114860355354624                                               VAMO   \n",
       "1363559739808956416  @SelecaoTalk Even if flamengo win today, they ...   \n",
       "1363617157846863880                            https://t.co/B0u9Y6fPAL   \n",
       "1363544459850481672  @marinofilho @luizmarquesdias Eu quero que o F...   \n",
       "1363595061808795650  @Flamengo SEGUE O L√çDERRRRR https://t.co/yFP2h...   \n",
       "1363559646536097793              cabelin na r√©gua e camisa do Flamengo   \n",
       "1363603541122809857             @Pedro9oficial @Flamengo Brabissimo üî¥‚ö´   \n",
       "1365119513105227776                   Flamengo ou cavalo paraguaio ? ü§£   \n",
       "1364978235331731456  VOCE RECEBEU O DESPERTADOR DA SORTE \\n\\n‚è∞‚è∞‚è∞‚è∞‚è∞‚è∞...   \n",
       "1363617280446373891                            Te amo @Flamengo ‚ù§Ô∏èüñ§‚ù§Ô∏èüñ§   \n",
       "1363574773599637506       me SEGUE quem acha que o Flamengo vai ganhar   \n",
       "1364970431384584197  @flaesports @Brasileirao @Flamengo √© exatament...   \n",
       "1363562504283160591      Falta pouco pro jogo come√ßar . Vamos Flamengo   \n",
       "1364963189784477706     Se o Flamengo ganhar vai ter algo na rua hoje?   \n",
       "1363601596941291529  @AcidoPH2O @perboni_ @RenataBFan Dos lances co...   \n",
       "1364980236119646211  @macgaren Eu so n√£o quero ver o Flamengo campe...   \n",
       "1363618204845752322                  Flamengo! https://t.co/spPbwO9IQ2   \n",
       "1364964693169889282  EU NASCI FLAMENGO E SEMPRE VOU TE AMAR NAO IMP...   \n",
       "1365093267776434179                    Ai Flamengo, por favor üôèüèΩüôèüèΩüôèüèΩüôèüèΩ   \n",
       "1363605164310069248  @Paitalok @LuscaSanttoos @O_tal_do_Renan7 @The...   \n",
       "\n",
       "                                                     preprocessed_text  \\\n",
       "id_str                                                                   \n",
       "1365114860355354624                                               vamo   \n",
       "1363559739808956416  even if flamengo win today they might lose to ...   \n",
       "1363617157846863880                                                      \n",
       "1363544459850481672  eu quero que o flamengo se foda meus amigo se ...   \n",
       "1363595061808795650                                  segue o l√≠derrrrr   \n",
       "1363559646536097793              cabelin na r√©gua e camisa do flamengo   \n",
       "1363603541122809857                                         brabissimo   \n",
       "1365119513105227776                       flamengo ou cavalo paraguaio   \n",
       "1364978235331731456  voce recebeu o despertador da sorte repasse pr...   \n",
       "1363617280446373891                                             te amo   \n",
       "1363574773599637506       me segue quem acha que o flamengo vai ganhar   \n",
       "1364970431384584197  √© exatamente isso que voc√™ leu mandar √©ofinal ...   \n",
       "1363562504283160591        falta pouco pro jogo come√ßar vamos flamengo   \n",
       "1364963189784477706      se o flamengo ganhar vai ter algo na rua hoje   \n",
       "1363601596941291529  dos lances contra o pr√≥prio flamengo no primei...   \n",
       "1364980236119646211   eu so n√£o quero ver o flamengo campe√£o novamente   \n",
       "1363618204845752322                                           flamengo   \n",
       "1364964693169889282  eu nasci flamengo e sempre vou te amar nao imp...   \n",
       "1365093267776434179                              ai flamengo por favor   \n",
       "1363605164310069248  sim ai √© com ele se eles apitam pros dois lado...   \n",
       "\n",
       "                                                         liwc_analysis  \\\n",
       "id_str                                                                   \n",
       "1365114860355354624                                                 {}   \n",
       "1363559739808956416  {'adj (Adjectives)': 1, 'relativ (Relativity)'...   \n",
       "1363617157846863880                                                 {}   \n",
       "1363544459850481672  {'function (Function Words)': 6, 'pronoun (Pro...   \n",
       "1363595061808795650  {'function (Function Words)': 2, 'auxverb (Aux...   \n",
       "1363559646536097793  {'function (Function Words)': 3, 'article (Art...   \n",
       "1363603541122809857                                                 {}   \n",
       "1365119513105227776  {'function (Function Words)': 1, 'conj (Conjun...   \n",
       "1364978235331731456  {'function (Function Words)': 7, 'pronoun (Pro...   \n",
       "1363617280446373891  {'function (Function Words)': 1, 'pronoun (Pro...   \n",
       "1363574773599637506  {'function (Function Words)': 6, 'pronoun (Pro...   \n",
       "1364970431384584197  {'function (Function Words)': 8, 'auxverb (Aux...   \n",
       "1363562504283160591  {'verb (Verbs)': 4, 'affect (Affect)': 2, 'neg...   \n",
       "1364963189784477706  {'function (Function Words)': 7, 'pronoun (Pro...   \n",
       "1363601596941291529  {'function (Function Words)': 8, 'article (Art...   \n",
       "1364980236119646211  {'function (Function Words)': 4, 'pronoun (Pro...   \n",
       "1363618204845752322                                                 {}   \n",
       "1364964693169889282  {'function (Function Words)': 10, 'pronoun (Pr...   \n",
       "1365093267776434179  {'affect (Affect)': 2, 'negemo (Negative Emoti...   \n",
       "1363605164310069248  {'function (Function Words)': 6, 'adverb (Adve...   \n",
       "\n",
       "                     is_subjective  \n",
       "id_str                              \n",
       "1365114860355354624              0  \n",
       "1363559739808956416              0  \n",
       "1363617157846863880              0  \n",
       "1363544459850481672              1  \n",
       "1363595061808795650              0  \n",
       "1363559646536097793              0  \n",
       "1363603541122809857              0  \n",
       "1365119513105227776              1  \n",
       "1364978235331731456              1  \n",
       "1363617280446373891              0  \n",
       "1363574773599637506              1  \n",
       "1364970431384584197              0  \n",
       "1363562504283160591              1  \n",
       "1364963189784477706              1  \n",
       "1363601596941291529              1  \n",
       "1364980236119646211              1  \n",
       "1363618204845752322              0  \n",
       "1364964693169889282              1  \n",
       "1365093267776434179              1  \n",
       "1363605164310069248              1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>preprocessed_text</th>\n      <th>liwc_analysis</th>\n      <th>is_subjective</th>\n    </tr>\n    <tr>\n      <th>id_str</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1365114860355354624</th>\n      <td>VAMO</td>\n      <td>vamo</td>\n      <td>{}</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363559739808956416</th>\n      <td>@SelecaoTalk Even if flamengo win today, they ...</td>\n      <td>even if flamengo win today they might lose to ...</td>\n      <td>{'adj (Adjectives)': 1, 'relativ (Relativity)'...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363617157846863880</th>\n      <td>https://t.co/B0u9Y6fPAL</td>\n      <td></td>\n      <td>{}</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363544459850481672</th>\n      <td>@marinofilho @luizmarquesdias Eu quero que o F...</td>\n      <td>eu quero que o flamengo se foda meus amigo se ...</td>\n      <td>{'function (Function Words)': 6, 'pronoun (Pro...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1363595061808795650</th>\n      <td>@Flamengo SEGUE O L√çDERRRRR https://t.co/yFP2h...</td>\n      <td>segue o l√≠derrrrr</td>\n      <td>{'function (Function Words)': 2, 'auxverb (Aux...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363559646536097793</th>\n      <td>cabelin na r√©gua e camisa do Flamengo</td>\n      <td>cabelin na r√©gua e camisa do flamengo</td>\n      <td>{'function (Function Words)': 3, 'article (Art...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363603541122809857</th>\n      <td>@Pedro9oficial @Flamengo Brabissimo üî¥‚ö´</td>\n      <td>brabissimo</td>\n      <td>{}</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1365119513105227776</th>\n      <td>Flamengo ou cavalo paraguaio ? ü§£</td>\n      <td>flamengo ou cavalo paraguaio</td>\n      <td>{'function (Function Words)': 1, 'conj (Conjun...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1364978235331731456</th>\n      <td>VOCE RECEBEU O DESPERTADOR DA SORTE \\n\\n‚è∞‚è∞‚è∞‚è∞‚è∞‚è∞...</td>\n      <td>voce recebeu o despertador da sorte repasse pr...</td>\n      <td>{'function (Function Words)': 7, 'pronoun (Pro...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1363617280446373891</th>\n      <td>Te amo @Flamengo ‚ù§Ô∏èüñ§‚ù§Ô∏èüñ§</td>\n      <td>te amo</td>\n      <td>{'function (Function Words)': 1, 'pronoun (Pro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363574773599637506</th>\n      <td>me SEGUE quem acha que o Flamengo vai ganhar</td>\n      <td>me segue quem acha que o flamengo vai ganhar</td>\n      <td>{'function (Function Words)': 6, 'pronoun (Pro...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1364970431384584197</th>\n      <td>@flaesports @Brasileirao @Flamengo √© exatament...</td>\n      <td>√© exatamente isso que voc√™ leu mandar √©ofinal ...</td>\n      <td>{'function (Function Words)': 8, 'auxverb (Aux...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1363562504283160591</th>\n      <td>Falta pouco pro jogo come√ßar . Vamos Flamengo</td>\n      <td>falta pouco pro jogo come√ßar vamos flamengo</td>\n      <td>{'verb (Verbs)': 4, 'affect (Affect)': 2, 'neg...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1364963189784477706</th>\n      <td>Se o Flamengo ganhar vai ter algo na rua hoje?</td>\n      <td>se o flamengo ganhar vai ter algo na rua hoje</td>\n      <td>{'function (Function Words)': 7, 'pronoun (Pro...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1363601596941291529</th>\n      <td>@AcidoPH2O @perboni_ @RenataBFan Dos lances co...</td>\n      <td>dos lances contra o pr√≥prio flamengo no primei...</td>\n      <td>{'function (Function Words)': 8, 'article (Art...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1364980236119646211</th>\n      <td>@macgaren Eu so n√£o quero ver o Flamengo campe...</td>\n      <td>eu so n√£o quero ver o flamengo campe√£o novamente</td>\n      <td>{'function (Function Words)': 4, 'pronoun (Pro...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1363618204845752322</th>\n      <td>Flamengo! https://t.co/spPbwO9IQ2</td>\n      <td>flamengo</td>\n      <td>{}</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1364964693169889282</th>\n      <td>EU NASCI FLAMENGO E SEMPRE VOU TE AMAR NAO IMP...</td>\n      <td>eu nasci flamengo e sempre vou te amar nao imp...</td>\n      <td>{'function (Function Words)': 10, 'pronoun (Pr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1365093267776434179</th>\n      <td>Ai Flamengo, por favor üôèüèΩüôèüèΩüôèüèΩüôèüèΩ</td>\n      <td>ai flamengo por favor</td>\n      <td>{'affect (Affect)': 2, 'negemo (Negative Emoti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1363605164310069248</th>\n      <td>@Paitalok @LuscaSanttoos @O_tal_do_Renan7 @The...</td>\n      <td>sim ai √© com ele se eles apitam pros dois lado...</td>\n      <td>{'function (Function Words)': 6, 'adverb (Adve...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    1171\n",
       "0     829\n",
       "Name: is_subjective, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df.is_subjective.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/data.xlsx')"
   ]
  }
 ]
}